package edu.nyu.rbda;

import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class WordCountMapper extends Mapper<LongWritable, Text, Text, IntWritable> {
	@Override
	public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {

		Configuration conf = context.getConfiguration();
		ArrayList<String> searchStrings = new ArrayList<String>(Arrays.asList(conf.getStrings("wordsToSearch")));

		String line = value.toString();
		String[] tokens = line.split("d*[.@:=#\\-,/ ]");

		for (String token : tokens) {
			for (String searchString : searchStrings) {
				if (searchString.equalsIgnoreCase(token)) {
					context.write(new Text(token), new IntWritable(1));
				}
			}
			searchStrings.remove(searchString);
		}

		for (String searchString : searchStrings) {
			context.write(new Text(searchString), new IntWritable(0));
		}

	}
}
